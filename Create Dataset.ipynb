{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, LEDModel\n",
    "import torch\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"Yashaswat/Indian-Legal-Text-ABS\")\n",
    "split = dataset['train'].select(range(2000))\n",
    "\n",
    "# Load model\n",
    "model_name = \"allenai/led-base-16384\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = LEDModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return np.zeros(model.config.hidden_size)\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(\n",
    "            text, return_tensors=\"pt\", \n",
    "            truncation=True, max_length=1024, \n",
    "            padding=\"max_length\"\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs).last_hidden_state\n",
    "            return output.mean(dim=1).squeeze().cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return np.zeros(model.config.hidden_size)\n",
    "\n",
    "def extract_summary(judgement, top_k=15):\n",
    "    sentences = [s for s in nltk.sent_tokenize(judgement) if s.strip()]\n",
    "    if len(sentences) <= top_k:\n",
    "        return \" \".join(sentences)\n",
    "    \n",
    "    embeddings = []\n",
    "    batch_size = 8  # Adjust based on your GPU memory\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        embeddings.extend(get_sentence_embedding(sent) for sent in batch)\n",
    "    \n",
    "    doc_embedding = np.mean(embeddings, axis=0)\n",
    "    sims = cosine_similarity(embeddings, [doc_embedding]).flatten()\n",
    "    top_indices = np.argsort(sims)[-top_k:]\n",
    "    \n",
    "    return \" \".join([sentences[i] for i in sorted(top_indices)])\n",
    "\n",
    "# Process with memory management\n",
    "extractive_summaries = []\n",
    "for row in tqdm(split, desc=\"Processing\"):\n",
    "    try:\n",
    "        summary = extract_summary(row['judgement'])\n",
    "        extractive_summaries.append(summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on row: {e}\")\n",
    "        extractive_summaries.append(\"\")\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame(split)\n",
    "df[\"extractive_summary\"] = extractive_summaries\n",
    "df.to_csv(\"train_2000_extractive_summary_led.csv\", index=False)\n",
    "print(\"âœ… Summaries saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(extractive_summaries, columns=['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('extractive_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From the Judgment and Order dated 25 6 74 of the Karna taka 'High Court in Civil Revision No 1981/73. This appeal by special leave is from the judgment .dated 25 June, 1974 of the Karnataka High Court. The respondent filed a suit for the grant of a permanent injunction restraining the appellant from interfering with the possession. The respondent contended that he was still a tenant. The appellant obtained a decree in the suit. Upon remand the respondent applied for the amendment of the written statement. The respondent claimed protection under the Karnataka Land Reforms Act, 1961. The appellant opposed the application for stay of the suit by the civil court and referring to the Tribunal for decision under the Karnataka Land Reforms Act, 1961. The trial Court dismissed the application of the respondent. The suit is for recovery of possession and for damages, for unauthorised occupation of the respondent. Therefore, no question can be referred for determination by the Tribunal under section 133. The re spondent could not draw any support from that Act for pro tection against eviction. The trial Court in the present case rightly said that it could not be said that there was any dispute as to tenancy. 272 The respondent had filed a suit where he claimed to remain in possession. The suit of the respondent was dismissed.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractive_summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ptorch)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
